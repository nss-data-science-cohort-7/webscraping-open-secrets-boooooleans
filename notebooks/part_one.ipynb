{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import random\n",
    "%run ../data/states_districts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.79 Safari/537.36 Edge/14.14931\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; AS; rv:11.0) like Gecko\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/17.17134\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 5.1; rv:7.0.1) Gecko/20100101 Firefox/7.0.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; AS; rv:11.0) like Gecko\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:15.0) Gecko/20100101 Firefox/15.0.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/18.17763\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36\",\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_candidate_data(state_district):\n",
    "    headers = {\n",
    "    'User-Agent': random.choice(user_agents)\n",
    "    }\n",
    "    endpoint = f'https://www.opensecrets.org/races/candidates?cycle=2020&id={state_district}&spec=N'\n",
    "\n",
    "    timeout = aiohttp.ClientTimeout(total=600)\n",
    "    connector = aiohttp.TCPConnector(limit=10)\n",
    "    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:\n",
    "        async with session.get(endpoint, headers=headers) as res:\n",
    "            if res.status == 200:  # HTTP Status Code 200 means OK\n",
    "                text = await res.text()\n",
    "                soup = BeautifulSoup(text, 'html.parser')\n",
    "            else:\n",
    "                print(f\"Failed to retrieve {endpoint}: {res.status}\")\n",
    "                return []  # Return an empty list or another suitable default value\n",
    "\n",
    "    \n",
    "    pattern_candidate = re.compile(r\"(.+?) \\((R|D|I)\\)( •Incumbent•Winner)?(\\(([\\d.]+)% of vote\\))?\")\n",
    "    pandas_data = []\n",
    "    \n",
    "    # Extract candidate data\n",
    "    for element in soup.find_all('h2'):\n",
    "        text = element.get_text(strip=True)\n",
    "        match = pattern_candidate.match(text)\n",
    "        if match:\n",
    "            name, party, incumbent_winner, _, vote_percentage = match.groups()\n",
    "            incumbent = incumbent_winner is not None\n",
    "            winner = incumbent  # Assumes if they are incumbent they are also the winner\n",
    "            pandas_data.append({\n",
    "                \"Name\": name,\n",
    "                \"Party\": party,\n",
    "                \"Incumbent\": incumbent,\n",
    "                \"Winner\": winner,\n",
    "                \"Vote Percentage\": vote_percentage,\n",
    "                \"Raised\": None,\n",
    "                \"Spent\": None\n",
    "            })\n",
    "\n",
    "    financial_data = []\n",
    "\n",
    "    # Loop through all the tables with class 'Members--table'\n",
    "    for table in soup.find_all('table', class_='Members--table'):\n",
    "        # Initialize a dictionary to store the raised and spent values for this table\n",
    "        table_data = {}\n",
    "        \n",
    "        # Loop through all the tr elements in the table\n",
    "        for row in table.find_all('tr'):\n",
    "            # Get the text content of all td elements in the row\n",
    "            cols = [col.get_text() for col in row.find_all('td')]\n",
    "            \n",
    "            # Check if the first column is 'Raised' or 'Spent', and if so, store the data\n",
    "            if cols[0] == 'Raised:':\n",
    "                table_data['Raised'] = cols[1]\n",
    "            elif cols[0] == 'Spent:':\n",
    "                table_data['Spent'] = cols[1]\n",
    "        \n",
    "        # Append the data dictionary to the financial_data list\n",
    "        financial_data.append(table_data)\n",
    "\n",
    "    # Check if lengths of pandas_data and financial_data match\n",
    "    if len(pandas_data) == len(financial_data):\n",
    "        # Update pandas_data with financial data\n",
    "        for p_data, f_data in zip(pandas_data, financial_data):\n",
    "            p_data.update(f_data)\n",
    "    else:\n",
    "        print(f\"Mismatch in the number of entries between candidate data and financial data for {state_district}\")\n",
    "\n",
    "    return pandas_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch in the number of entries between candidate data and financial data for CA29\n",
      "Mismatch in the number of entries between candidate data and financial data for CO06\n",
      "Mismatch in the number of entries between candidate data and financial data for CO03\n",
      "Mismatch in the number of entries between candidate data and financial data for CO05\n",
      "Mismatch in the number of entries between candidate data and financial data for CT03\n",
      "Mismatch in the number of entries between candidate data and financial data for GA08\n",
      "Mismatch in the number of entries between candidate data and financial data for GA05\n",
      "Mismatch in the number of entries between candidate data and financial data for GA13\n",
      "Mismatch in the number of entries between candidate data and financial data for IL06\n",
      "Mismatch in the number of entries between candidate data and financial data for HI02\n",
      "Mismatch in the number of entries between candidate data and financial data for IN09\n",
      "Mismatch in the number of entries between candidate data and financial data for IL07\n",
      "Mismatch in the number of entries between candidate data and financial data for UT04\n",
      "Mismatch in the number of entries between candidate data and financial data for KY02\n",
      "Mismatch in the number of entries between candidate data and financial data for MI02\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MS04&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MD02&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MS03&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MO03&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MT01&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI10&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=LA03&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MN01&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MD01&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI07&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MN04&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MN05&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MA05&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=KY03&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI13&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=IL08&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI12&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI09&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MN08&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MN03&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MN02&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI11&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MN06&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MA06&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=ME02&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MO04&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MO02&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI03&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MD07&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=MI06&spec=N: 429\n",
      "Failed to retrieve https://www.opensecrets.org/races/candidates?cycle=2020&id=AS00&spec=N: 429\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m all_data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# To run your async function in Jupyter, you could use:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m all_scraped_data \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m fetch_all_data()\n",
      "\u001b[1;32m/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m# print(webpage)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         tasks\u001b[39m.\u001b[39mappend(scrape_candidate_data(webpage))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_data\u001b[39m.\u001b[39mextend(\u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39mtasks))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m all_data\n",
      "\u001b[1;32m/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m connector \u001b[39m=\u001b[39m aiohttp\u001b[39m.\u001b[39mTCPConnector(limit\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m aiohttp\u001b[39m.\u001b[39mClientSession(connector\u001b[39m=\u001b[39mconnector, timeout\u001b[39m=\u001b[39mtimeout) \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m session\u001b[39m.\u001b[39mget(endpoint, headers\u001b[39m=\u001b[39mheaders) \u001b[39mas\u001b[39;00m res:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:  \u001b[39m# HTTP Status Code 200 means OK\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/treyshanks/data_science/webscraping-open-secrets-boooooleans/notebooks/part_one.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             text \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m res\u001b[39m.\u001b[39mtext()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/aiohttp/client.py:1141\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m__aenter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _RetType:\n\u001b[0;32m-> 1141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resp \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coro\n\u001b[1;32m   1142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resp\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/aiohttp/client.py:467\u001b[0m, in \u001b[0;36mClientSession._request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx, read_bufsize)\u001b[0m\n\u001b[1;32m    465\u001b[0m timer \u001b[39m=\u001b[39m tm\u001b[39m.\u001b[39mtimer()\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mwith\u001b[39;00m timer:\n\u001b[1;32m    468\u001b[0m         \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m             url, auth_from_url \u001b[39m=\u001b[39m strip_auth_from_url(url)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/aiohttp/helpers.py:720\u001b[0m, in \u001b[0;36mTimerContext.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks\u001b[39m.\u001b[39mpop()\n\u001b[1;32m    719\u001b[0m \u001b[39mif\u001b[39;00m exc_type \u001b[39mis\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cancelled:\n\u001b[0;32m--> 720\u001b[0m     \u001b[39mraise\u001b[39;00m asyncio\u001b[39m.\u001b[39mTimeoutError \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async def fetch_all_data():\n",
    "    all_data = []\n",
    "    tasks = []\n",
    "    for state in congressional_districts:\n",
    "        for district in congressional_districts[state]:\n",
    "            webpage = state + district\n",
    "            # print(webpage)\n",
    "            tasks.append(scrape_candidate_data(webpage))\n",
    "    all_data.extend(await asyncio.gather(*tasks))\n",
    "    return all_data\n",
    "\n",
    "# To run your async function in Jupyter, you could use:\n",
    "all_scraped_data = await fetch_all_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
